{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgt55TQpeInx"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric biopython fair-esm tqdm # install this running baseline GCN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/02703/9606' # replace with your own"
      ],
      "metadata": {
        "id": "38Mg_6CyXznj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running any of the cells, please download 9606.protein.physical.links.v12.0.txt, 9606.protein.enrichment.terms.v12.0.txt, 9606.protein.sequences.v12.0.fa, 9606.protein.aliases.v12.0.txt into your [BASE_DIR], we will need the first two files to construct PPIN, and latter two to extract ESM embeddings and 3D structure data.\n",
        "\n",
        "To install package for running baseline GCN, run:\n",
        "\n",
        "pip install torch-geometric biopython fair-esm tqdm\n",
        "\n",
        "For the pacakges to run GVP, there is a section afterwards to install dgl\n",
        "\n"
      ],
      "metadata": {
        "id": "1Xy9SuxWX0_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct PPIN"
      ],
      "metadata": {
        "id": "aduCtNtckuKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCZSktVNfe97"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PPI_LINKS_PATH = os.path.join(BASE_DIR, '9606.protein.physical.links.v12.0.txt')\n",
        "GO_TERMS_PATH = os.path.join(BASE_DIR, '9606.protein.enrichment.terms.v12.0.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn4f5YLrv7CL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qua3RKxGhy_h"
      },
      "outputs": [],
      "source": [
        "def load_ppi_links(fpath):\n",
        "    protein_set = set()\n",
        "    edge_list = []\n",
        "    with open(fpath, 'r') as file:\n",
        "        next(file)  # Skip header\n",
        "        for line in file:\n",
        "            p1, p2, score = line.strip().split()\n",
        "            edge_list.append((p1, p2))\n",
        "            protein_set.add(p1)\n",
        "            protein_set.add(p2)\n",
        "    return list(protein_set), edge_list\n",
        "\n",
        "proteins, edge_list = load_ppi_links(PPI_LINKS_PATH)\n",
        "\n",
        "# Step 3: Load GO terms\n",
        "def load_go_terms(fpath, target_category=\"Molecular Function (Gene Ontology)\"):\n",
        "    go_term_dict = {}\n",
        "    with open(fpath, 'r') as file:\n",
        "        next(file)  # Skip header\n",
        "        for line in file:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 4:\n",
        "                string_id, category, term, desc = parts\n",
        "                if category == target_category:\n",
        "                    if string_id not in go_term_dict:\n",
        "                        go_term_dict[string_id] = []\n",
        "                    go_term_dict[string_id].append(term)\n",
        "    return go_term_dict\n",
        "\n",
        "go_terms = load_go_terms(GO_TERMS_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "PSWgebVJkx3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOPZavxzjiR5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "proteins_with_labels = [protein for protein in proteins if protein in go_terms]\n",
        "filtered_labels = [go_terms[protein] for protein in proteins_with_labels]\n",
        "filtered_mlb = MultiLabelBinarizer()\n",
        "filtered_y = filtered_mlb.fit_transform(filtered_labels)\n",
        "data_y = torch.tensor(filtered_y, dtype=torch.float)\n",
        "\n",
        "# Map proteins to indices and create filtered edge index\n",
        "protein_to_idx = {protein: i for i, protein in enumerate(proteins_with_labels)}\n",
        "filtered_edge_list = [(protein_to_idx[p1], protein_to_idx[p2])\n",
        "                      for p1, p2 in edge_list if p1 in protein_to_idx and p2 in protein_to_idx]\n",
        "filtered_edge_index = torch.tensor(filtered_edge_list, dtype=torch.long).t().contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Train/Val/Test split\n",
        "num_proteins = len(proteins_with_labels)\n",
        "train_indices, test_indices = train_test_split(range(num_proteins), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_indices, test_size=0.25, random_state=42)  # 60% train, 20% val, 20% test\n",
        "\n",
        "train_mask = torch.zeros(num_proteins, dtype=torch.bool)\n",
        "val_mask = torch.zeros(num_proteins, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_proteins, dtype=torch.bool)\n",
        "train_mask[train_indices] = True\n",
        "val_mask[val_indices] = True\n",
        "test_mask[test_indices] = True"
      ],
      "metadata": {
        "id": "9_ggehw3z2IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkHNw_P9tgaG"
      },
      "source": [
        "# Baseline GCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb9cJ30w12VO"
      },
      "source": [
        "## GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wplc6TDCiiwc"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiBqMGGuruVS"
      },
      "outputs": [],
      "source": [
        "# one-hot encoding\n",
        "num_unique_proteins = len(set(proteins_with_labels))  # Count unique proteins\n",
        "one_hot_features = torch.eye(num_unique_proteins)\n",
        "\n",
        "# zero features encoding\n",
        "feature_dim = 1  # Minimal feature dimension; can be adjusted if needed\n",
        "minimal_features = torch.zeros((len(proteins_with_labels), feature_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prpgk5Fzt3BO"
      },
      "outputs": [],
      "source": [
        "# Create data objects for one-hot\n",
        "minimal_features_data = Data(x=minimal_features, edge_index=filtered_edge_index, y=data_y,\n",
        "                   train_mask=train_mask, val_mask=val_mask, test_mask=test_mask).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0Nvw6KKI-7g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydYVwAX8uh3L"
      },
      "outputs": [],
      "source": [
        "# Define training function\n",
        "def train_minibatch_model(model, train_loader, val_loader, optimizer, criterion, epochs=100):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch.x.to(device), batch.edge_index.to(device))\n",
        "            loss = criterion(out[batch.train_mask].to(device), batch.y[batch.train_mask].to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                out = model(batch.x.to(device), batch.edge_index.to(device))\n",
        "                loss = criterion(out[batch.val_mask].to(device), batch.y[batch.val_mask].to(device))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "        # Print progress\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_minibatch_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            out = model(batch.x.to(device), batch.edge_index.to(device))\n",
        "            preds = torch.sigmoid(out[batch.test_mask].to(device)) > 0.5\n",
        "            predictions.append(preds.cpu())\n",
        "            labels.append(batch.y[batch.test_mask].cpu())\n",
        "\n",
        "    predictions = torch.cat(predictions, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = (predictions == labels).sum().item() / labels.numel()\n",
        "    f1 = f1_score(labels, predictions, average=\"micro\")\n",
        "    precision = precision_score(labels, predictions, average=\"micro\")\n",
        "    recall = recall_score(labels, predictions, average=\"micro\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "    return accuracy, f1, precision, recall\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import NeighborLoader\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    minimal_features_data,\n",
        "    num_neighbors=[10, 10],\n",
        "    input_nodes=minimal_features_data.train_mask,\n",
        "    batch_size=128,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = NeighborLoader(\n",
        "    minimal_features_data,\n",
        "    num_neighbors=[10, 10],\n",
        "    input_nodes=minimal_features_data.val_mask,\n",
        "    batch_size=128,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = NeighborLoader(\n",
        "    minimal_features_data,\n",
        "    num_neighbors=[10, 10],\n",
        "    input_nodes=minimal_features_data.test_mask,\n",
        "    batch_size=128,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "WMDK9SIi_LKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaeXLG2gyZ9D"
      },
      "outputs": [],
      "source": [
        "# Initialize models, loss, and optimizers\n",
        "hidden_dim = 8\n",
        "output_dim = data_y.shape[1]  # Number of unique GO terms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "\n"
      ],
      "metadata": {
        "id": "Oepaenz-_nbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toiw9MCqDrLV"
      },
      "outputs": [],
      "source": [
        "# min feature Model\n",
        "min_feat_model = GCNModel(input_dim=minimal_features_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = AdamW(min_feat_model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train and evaluate the min-feat encoding model\n",
        "print(\"Training min-feat Encoding Model\")\n",
        "min_feat_train_losses, min_feat_val_losses = train_minibatch_model(min_feat_model, train_loader, val_loader, optimizer, criterion, epochs=150)\n",
        "\n",
        "print(\"\\nFinal Evaluation on Test Set (min-feat Encoding Model)\")\n",
        "evaluate_minibatch_model(min_feat_model, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "def compute_metrics(predictions, labels, thresholds=np.linspace(0, 1, 101)):\n",
        "    \"\"\"\n",
        "    predictions: numpy array of shape (num_proteins, num_terms), predicted probabilities\n",
        "    labels: numpy array of shape (num_proteins, num_terms)\n",
        "    thresholds: array-like, list of thresholds to evaluate for Fmax\n",
        "\n",
        "    Returns:\n",
        "        fmax: Average maximum F1 score across proteins\n",
        "        aupr: Average area under precision-recall curve across GO terms\n",
        "        f1_max_scores: numpy array of fmax_values\n",
        "        aupr_scores: numpy array of aupr values\n",
        "    \"\"\"\n",
        "    num_proteins, num_terms = labels.shape\n",
        "\n",
        "    f1_max_scores = []\n",
        "    for i in range(num_proteins):\n",
        "        protein_preds = predictions[i]\n",
        "        protein_labels = labels[i]\n",
        "\n",
        "        max_f1 = 0\n",
        "        for t in thresholds:\n",
        "            binary_preds = (protein_preds >= t).astype(int)\n",
        "            tp = np.sum((binary_preds == 1) & (protein_labels == 1))\n",
        "            fp = np.sum((binary_preds == 1) & (protein_labels == 0))\n",
        "            fn = np.sum((binary_preds == 0) & (protein_labels == 1))\n",
        "\n",
        "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
        "            max_f1 = max(max_f1, f1)\n",
        "\n",
        "        f1_max_scores.append(max_f1)\n",
        "\n",
        "    fmax = np.mean(f1_max_scores)\n",
        "\n",
        "    aupr_scores = []\n",
        "    for j in range(num_terms):\n",
        "        term_preds = predictions[:, j]\n",
        "        term_labels = labels[:, j]\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(term_labels, term_preds)\n",
        "        aupr = auc(recall, precision)\n",
        "        aupr_scores.append(aupr)\n",
        "\n",
        "    aupr = np.mean(aupr_scores)\n",
        "\n",
        "    return fmax, aupr, f1_max_scores, aupr_scores\n",
        "\n",
        "\n",
        "def evaluate_minibatch_model_with_metrics(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            out = model(batch.x.to(device), batch.edge_index.to(device))\n",
        "            preds = torch.sigmoid(out[batch.test_mask]).cpu()\n",
        "            predictions.append(preds)\n",
        "            labels.append(batch.y[batch.test_mask].cpu())\n",
        "\n",
        "    # Combine predictions and labels across all batches\n",
        "    predictions = torch.cat(predictions, dim=0).numpy()\n",
        "    labels = torch.cat(labels, dim=0).numpy()\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = (predictions.round() == labels).sum() / labels.size\n",
        "    f1 = f1_score(labels, predictions.round(), average=\"micro\")\n",
        "    precision = precision_score(labels, predictions.round(), average=\"micro\")\n",
        "    recall = recall_score(labels, predictions.round(), average=\"micro\")\n",
        "\n",
        "    # Compute Fmax and AUPR\n",
        "    fmax, aupr, f1_max_scores, aupr_scores = compute_metrics(predictions, labels)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"Fmax: {fmax:.4f}\")\n",
        "    print(f\"AUPR: {aupr:.4f}\")\n",
        "    return accuracy, f1, precision, recall, fmax, aupr\n",
        "\n",
        "# min_feat_model = GCNModel(input_dim=minimal_features_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "# min_feat_model.load_state_dict(torch.load('/content/drive/MyDrive/02703/9606/weights/gcn_model.pth'))\n",
        "\n",
        "# evaluete on test set\n",
        "print(\"\\nFinal Evaluation on Test Set (min-feat Encoding Model)\")\n",
        "evaluate_minibatch_model_with_metrics(min_feat_model, test_loader)"
      ],
      "metadata": {
        "id": "R02XIBW3EJHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF2A8oyN14Md"
      },
      "source": [
        "## GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFJhKdiX2Kdv"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GATModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads=8, dropout=0.5):\n",
        "        super(GATModel, self).__init__()\n",
        "        # Define the first GAT layer with multi-head attention\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout)\n",
        "        # Define the second GAT layer, combining heads\n",
        "        self.gat2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy8qXeQB2QUD"
      },
      "outputs": [],
      "source": [
        "# One-Hot Model\n",
        "onehot_gat = GATModel(input_dim=onehot_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim)\n",
        "optimizer_onehot_gat = AdamW(onehot_gat.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train and evaluate the one-hot encoding model\n",
        "print(\"Training One-Hot Encoding Model\")\n",
        "onehot_gat_train_losses, onehot_gat_val_losses = train_model(onehot_gat, onehot_data, optimizer_onehot_gat, criterion, epochs=150)\n",
        "print(\"\\nFinal Evaluation on Test Set (One-Hot Encoding Model)\")\n",
        "evaluate_model(onehot_gat, onehot_data, mask=onehot_data.test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC6i5FI1Sl5A"
      },
      "outputs": [],
      "source": [
        "# ESM Model\n",
        "esm_gat = GATModel(input_dim=esm_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim)\n",
        "optimizer_esm_gat = AdamW(esm_gat.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train and evaluate the one-hot encoding model\n",
        "print(\"Training ESM Encoding Model\")\n",
        "esm_gat_train_losses, esm_gat_val_losses = train_model(esm_gat, esm_data, optimizer_esm_gat, criterion, epochs=150)\n",
        "print(\"\\nFinal Evaluation on Test Set (ESM Encoding Model)\")\n",
        "evaluate_model(esm_gat, esm_data, mask=esm_data.test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V93yjOsc2QWw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(onehot_train_losses, label=\"GCN (onehot) Train Loss\")\n",
        "plt.plot(onehot_val_losses, label=\"GCN (onehot) Val Loss\")\n",
        "plt.plot(esm_train_losses, label=\"GCN (onehot + ESM) Train Loss\")\n",
        "plt.plot(esm_val_losses, label=\"GCN (onehot + ESM) Val Loss\")\n",
        "\n",
        "plt.plot(onehot_gat_train_losses, label=\"GAT (onehot) Train Loss\")\n",
        "plt.plot(onehot_gat_val_losses, label=\"GAT (onehot) Val Loss\")\n",
        "plt.plot(esm_gat_train_losses, label=\"GAT (onehot + ESM) Train Loss\")\n",
        "plt.plot(esm_gat_val_losses, label=\"GAT (onehot + ESM) Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Multi-label classification loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og0XxVmU2QY_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn6KYOtTGQ6g"
      },
      "source": [
        "# extract ESM embeddding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYMMhwYreqNw"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import esm\n",
        "from Bio import SeqIO\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/02703/9606'  # Update with your Google Drive or Colab path\n",
        "SEQUENCE_FILE = os.path.join(BASE_DIR, '9606.protein.sequences.v12.0.fa.gz')\n",
        "\n",
        "# Parse sequences from .fa.gz file using STRING IDs as keys\n",
        "def parse_sequences(sequence_file):\n",
        "    string_to_sequence = {}\n",
        "    with gzip.open(sequence_file, \"rt\") as f:\n",
        "        for record in SeqIO.parse(f, \"fasta\"):\n",
        "            string_id = record.id  # Directly use STRING ID from record.id\n",
        "            sequence = str(record.seq)\n",
        "            string_to_sequence[string_id] = sequence\n",
        "    return string_to_sequence\n",
        "\n",
        "# Load STRING sequences directly from the .fa.gz file\n",
        "string_to_sequence = parse_sequences(SEQUENCE_FILE)\n",
        "print(\"Sample STRING ID to sequence mapping:\", list(string_to_sequence.items())[:5])\n",
        "\n",
        "# Load pre-trained ESM model\n",
        "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
        "model = model.to(\"cuda\")  # Send model to GPU\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model.eval()\n",
        "\n",
        "# Generate ESM Embeddings\n",
        "protein_embeddings = []\n",
        "max_seq_len = 1022  # Truncate to avoid exceeding model's max length\n",
        "for protein in tqdm(list(string_to_sequence.keys()), desc=\"Generating ESM embeddings\"):\n",
        "    sequence = string_to_sequence[protein]\n",
        "    if sequence:\n",
        "        truncated_sequence = sequence[:max_seq_len]\n",
        "        batch_labels, batch_strs, batch_tokens = batch_converter([(protein, truncated_sequence)])\n",
        "        batch_tokens = batch_tokens.to(\"cuda\")  # Send tokens to GPU\n",
        "\n",
        "        with torch.no_grad():\n",
        "            results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
        "            token_representations = results[\"representations\"][33]\n",
        "            embedding = token_representations.mean(dim=1).squeeze().cpu()\n",
        "            protein_embeddings.append(embedding)\n",
        "    else:\n",
        "        protein_embeddings.append(torch.zeros(model.args.embed_dim))\n",
        "\n",
        "x = torch.stack(protein_embeddings)\n",
        "print(\"ESM Embeddings generated successfully.\")\n",
        "\n",
        "# Save embeddings to avoid regenerating them\n",
        "torch.save(x, \"/content/drive/MyDrive/02703/9606/protein_esm_embeddings.pt\") # save it under BASE_DIR\n",
        "print(\"ESM embeddings saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESM"
      ],
      "metadata": {
        "id": "7ha0ihV7Zw-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esm_data = Data(x=filtered_esm_embeddings, edge_index=filtered_edge_index, y=data_y,\n",
        "                train_mask=train_mask, val_mask=val_mask, test_mask=test_mask).to(device)"
      ],
      "metadata": {
        "id": "onl3NIGOhwKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create esm model\n",
        "esm_feat_model = GCNModel(input_dim=esm_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = AdamW(esm_feat_model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "esm_feat_train_losses, esm_feat_val_losses = train_minibatch_model(esm_feat_model, train_loader, val_loader, optimizer, criterion, epochs=150)"
      ],
      "metadata": {
        "id": "zHQ0_xcIhi5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jYL_JFxuUIc"
      },
      "outputs": [],
      "source": [
        "# ESM models\n",
        "esm_embeddings = torch.load(f\"{BASE_DIR}/protein_esm_embeddings.pt\")\n",
        "filtered_esm_embeddings = torch.stack([esm_embeddings[protein_to_idx[protein]]\n",
        "                                       for protein in proteins_with_labels])\n",
        "\n",
        "test_loader = NeighborLoader(\n",
        "    esm_data,\n",
        "    num_neighbors=[10, 10],\n",
        "    input_nodes=esm_data.test_mask,\n",
        "    batch_size=128,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "esm_model = GCNModel(input_dim=esm_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "esm_model.load_state_dict(torch.load('/content/drive/MyDrive/02703/9606/weights/gcn_esm_model.pth'))\n",
        "\n",
        "# evaluete on test set\n",
        "print(\"\\nFinal Evaluation on Test Set (ESM Encoding Model)\")\n",
        "evaluate_minibatch_model_with_metrics(esm_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ESM Model\n",
        "esm_embeddings = torch.load(f\"{BASE_DIR}/protein_esm_embeddings.pt\")\n",
        "filtered_esm_embeddings = torch.stack([esm_embeddings[protein_to_idx[protein]]\n",
        "                                       for protein in proteins_with_labels])\n",
        "esm_data = Data(x=filtered_esm_embeddings, edge_index=filtered_edge_index, y=data_y,\n",
        "                train_mask=train_mask, val_mask=val_mask, test_mask=test_mask).to(device)\n",
        "esm_model = GCNModel(input_dim=esm_data.num_features, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = AdamW(esm_model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train and evaluate the min-feat encoding model\n",
        "print(\"Training esm Encoding Model\")\n",
        "esm_train_losses,esm_val_losses = train_minibatch_model(esm_model, train_loader, val_loader, optimizer, criterion, epochs=150)"
      ],
      "metadata": {
        "id": "H7QcKEESwFfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR4kQwSapip4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(onehot_train_losses, label=\"One-Hot Training Loss\", color='blue')\n",
        "plt.plot(onehot_val_losses, label=\"One-Hot Validation Loss\", color='cyan')\n",
        "plt.plot(esm_train_losses, label=\"ESM Training Loss\", color='red')\n",
        "plt.plot(esm_val_losses, label=\"ESM Validation Loss\", color='orange')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"GCN using one-hot VS ESM embedding\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqLaXATZHRvA"
      },
      "source": [
        "# GVP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x449li9P4LJE"
      },
      "source": [
        "## extrat PDB files from AlphaFold using protein alias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCky2pgG4QKL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_aliases(base_dir):\n",
        "    \"\"\"\n",
        "    Extracts aliases from the alias file under the base directory.\n",
        "\n",
        "    :param base_dir: Directory containing input files, including the aliases file.\n",
        "    :return: A dictionary where keys are STRING protein IDs and values are lists of UniProt aliases.\n",
        "    \"\"\"\n",
        "    alias_file = os.path.join(base_dir, f'{base_dir}.protein.aliases.v12.0.txt')\n",
        "    alias_dict = {}\n",
        "\n",
        "    with open(alias_file, 'r') as file:\n",
        "        next(file)  # Skip the header\n",
        "        for line in file:\n",
        "            string_id, alias, source = line.strip().split('\\t')\n",
        "            if source == 'UniProt_AC':  # Filter for UniProt aliases\n",
        "                if string_id not in alias_dict:\n",
        "                    alias_dict[string_id] = []\n",
        "                alias_dict[string_id].append(alias)\n",
        "\n",
        "    print(f\"Extracted {len(alias_dict)} protein aliases from {alias_file}.\")\n",
        "    return alias_dict\n",
        "\n",
        "def download_structures(alias_dict, base_dir):\n",
        "    \"\"\"\n",
        "    Downloads PDB structure files for proteins using UniProt aliases from AlphaFold.\n",
        "    Saves the files in a 'structures' subdirectory under the specified base directory.\n",
        "\n",
        "    :param alias_dict: Dictionary where keys are STRING protein IDs and values are lists of UniProt aliases.\n",
        "    :param base_dir: Directory containing input files. The 'structures' directory will be created here.\n",
        "    \"\"\"\n",
        "    # Define the structures directory under the base directory\n",
        "    structures_dir = os.path.join(base_dir, \"structures\")\n",
        "    os.makedirs(structures_dir, exist_ok=True)  # Ensure the structures directory exists\n",
        "\n",
        "    total_proteins = len(alias_dict)\n",
        "    print(f\"Starting download for {total_proteins} proteins into '{structures_dir}'...\")\n",
        "\n",
        "    for protein in tqdm(alias_dict, desc=\"Downloading structures\"):\n",
        "        downloaded = False\n",
        "        for alias in alias_dict[protein]:\n",
        "            url = f'https://alphafold.ebi.ac.uk/files/AF-{alias}-F1-model_v4.pdb'\n",
        "            try:\n",
        "                response = requests.get(url, timeout=10)\n",
        "                if response.status_code == 200:\n",
        "                    file_path = os.path.join(structures_dir, f'{protein}.pdb')\n",
        "                    with open(file_path, 'wb') as file:\n",
        "                        file.write(response.content)\n",
        "                    downloaded = True\n",
        "                    break  # Exit loop after successful download\n",
        "            except requests.RequestException as e:\n",
        "                print(f\"Error downloading {protein} with alias {alias}: {e}\")\n",
        "\n",
        "        if not downloaded:\n",
        "            print(f\"Failed to download structure for protein {protein}.\")\n",
        "\n",
        "    print(f\"Download completed. Structures saved in '{structures_dir}'.\")\n",
        "\n",
        "base_dir = \"9606\"\n",
        "alias_dict = extract_aliases(base_dir)\n",
        "download_structures(alias_dict, base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LbBx7H04aAc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skh182lIua4f"
      },
      "source": [
        "## GVP + GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfyOa255GIN"
      },
      "source": [
        "## install correct version of dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1MdpVT86IL2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)  # Should match 2.0.1\n",
        "print(torch.cuda.is_available())  # Should return True\n",
        "print(torch.version.cuda)  # Should return '11.7' (from the above output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall -y torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "3lR7XGvh0s36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "id": "JNKfz7Cc07y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchdata==0.8.0"
      ],
      "metadata": {
        "id": "nh0Hwy0E0_91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html"
      ],
      "metadata": {
        "id": "E9K934E7lWDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Lhnpv_30wIWc"
      },
      "outputs": [],
      "source": [
        "# # install dgl for cpu\n",
        "# !pip uninstall -y torch torchvision torchaudio torchdata dgl\n",
        "# !pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cpu\n",
        "# !pip uninstall -y torchdata\n",
        "# !pip install torchdata==0.6.1  # Replace with the compatible version for PyTorch 2.5.1 if different\n",
        "# !pip install dgl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvPZacUWaD4E"
      },
      "outputs": [],
      "source": [
        "import dgl\n",
        "import torch\n",
        "\n",
        "# Check DGL version\n",
        "print(\"DGL version:\", dgl.__version__)\n",
        "\n",
        "# Check if DGL can access CUDA\n",
        "print(\"Is CUDA available in DGL:\", torch.cuda.is_available())\n",
        "\n",
        "# Create a simple graph and move it to the GPU\n",
        "g = dgl.graph(([0, 1], [1, 2])).to('cuda')\n",
        "print(\"Graph device:\", g.device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKXqMwvN5LZL"
      },
      "source": [
        "## Construct the graph with 3D structure data using dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW3mXoCh5qmo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnEX5Ud1rUOF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define amino acids for one-hot encoding\n",
        "amino_acids = [\n",
        "    \"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\",\n",
        "    \"GLU\", \"GLN\", \"GLY\", \"HIS\", \"ILE\",\n",
        "    \"LEU\", \"LYS\", \"MET\", \"PHE\", \"PRO\",\n",
        "    \"SER\", \"THR\", \"TRP\", \"TYR\", \"VAL\"\n",
        "]\n",
        "aa_to_index = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
        "\n",
        "def parse_pdb_residue_level(pdb_file_path):\n",
        "    \"\"\"\n",
        "    Parse residue-level features from a PDB file.\n",
        "\n",
        "    Args:\n",
        "        pdb_file_path: Path to the PDB file.\n",
        "\n",
        "    Returns:\n",
        "        coordinates: List of residue-level centroid coordinates.\n",
        "        scalar_features: List of one-hot encoded residue types.\n",
        "        missing: Boolean indicating if the file is missing or failed to parse.\n",
        "    \"\"\"\n",
        "    residues = {}\n",
        "    coordinates = []\n",
        "    scalar_features = []\n",
        "    missing = False\n",
        "\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        return coordinates, scalar_features, True\n",
        "\n",
        "    try:\n",
        "        with open(pdb_file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                if line.startswith(\"ATOM\") or line.startswith(\"HETATM\"):\n",
        "                    try:\n",
        "                        # Extract residue ID and atom coordinates\n",
        "                        residue_id = (line[21], int(line[22:26].strip()))  # Chain ID and Residue Number\n",
        "                        x = float(line[30:38].strip())\n",
        "                        y = float(line[38:46].strip())\n",
        "                        z = float(line[46:54].strip())\n",
        "\n",
        "                        # Extract residue type\n",
        "                        aa = line[17:20].strip()\n",
        "                        if residue_id not in residues:\n",
        "                            residues[residue_id] = {\"coords\": [], \"aa\": aa}\n",
        "\n",
        "                        residues[residue_id][\"coords\"].append([x, y, z])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "\n",
        "        # Compute residue centroids and one-hot encode residue types\n",
        "        for residue_id, residue_data in residues.items():\n",
        "            if residue_data[\"aa\"] in aa_to_index:\n",
        "                centroid = torch.tensor(residue_data[\"coords\"], dtype=torch.float).mean(dim=0)\n",
        "                one_hot = torch.zeros(len(amino_acids))\n",
        "                one_hot[aa_to_index[residue_data[\"aa\"]]] = 1.0\n",
        "                coordinates.append(centroid)\n",
        "                scalar_features.append(one_hot)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDB file {pdb_file_path}: {e}\")\n",
        "        missing = True\n",
        "\n",
        "    return coordinates, scalar_features, missing\n",
        "\n",
        "def prepare_features_with_coords(proteins, pdb_dir):\n",
        "    \"\"\"\n",
        "    Prepare residue-level features for a list of proteins.\n",
        "\n",
        "    Args:\n",
        "        proteins: List of protein IDs.\n",
        "        pdb_dir: Directory containing PDB files.\n",
        "\n",
        "    Returns:\n",
        "        scalar_features: Dictionary of scalar features for each protein.\n",
        "        vector_features: Dictionary of vector features for each protein.\n",
        "        coord_features: Dictionary of centroid coordinates for each protein.\n",
        "        missing_proteins: List of proteins missing PDB files.\n",
        "    \"\"\"\n",
        "    scalar_features = {}\n",
        "    vector_features = {}\n",
        "    coord_features = {}\n",
        "    missing_proteins = []\n",
        "\n",
        "    for protein in tqdm(proteins, desc=\"Processing proteins\"):\n",
        "        pdb_file = os.path.join(pdb_dir, f\"{protein}.pdb\")\n",
        "        coords, scalar_feats, missing = parse_pdb_residue_level(pdb_file)\n",
        "        if not missing:\n",
        "            coords_tensor = torch.stack(coords)\n",
        "            vector_feats = coords_tensor[1:] - coords_tensor[:-1]  # Residue-level vector differences\n",
        "            coord_features[protein] = coords_tensor  # All residue centroids\n",
        "            scalar_features[protein] = torch.stack(scalar_feats)  # All residue scalar features\n",
        "            vector_features[protein] = vector_feats\n",
        "        else:\n",
        "            missing_proteins.append(protein)\n",
        "\n",
        "    print(f\"Missing structures for {len(missing_proteins)} proteins.\")\n",
        "    return scalar_features, vector_features, coord_features, missing_proteins\n",
        "\n",
        "\n",
        "# Prepare features with coordinates\n",
        "scalar_feats_dict, vector_feats_dict, coord_feats_dict, missing_proteins = prepare_features_with_coords(\n",
        "    proteins_with_labels, \"/content/drive/MyDrive/02703/9606/structures/structures\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_features_to_graph(graph_nodes, scalar_feats_dict, vector_feats_dict, coord_feats_dict, max_scalar_len=None, max_vector_len=None):\n",
        "    \"\"\"\n",
        "    Align scalar, vector, and coordinate features to graph nodes.\n",
        "\n",
        "    Args:\n",
        "        graph_nodes: List of protein identifiers in the graph.\n",
        "        scalar_feats_dict: Dictionary of scalar features per protein.\n",
        "        vector_feats_dict: Dictionary of vector features per protein.\n",
        "        coord_feats_dict: Dictionary of coordinate features per protein.\n",
        "        max_scalar_len: Maximum length of scalar features (truncate/pad to this length).\n",
        "        max_vector_len: Maximum length of vector features (truncate/pad to this length).\n",
        "\n",
        "    Returns:\n",
        "        aligned_scalar_feats: Tensor of shape [num_graph_nodes, max_scalar_len, 20].\n",
        "        aligned_vector_feats: Tensor of shape [num_graph_nodes, max_vector_len, 3].\n",
        "        aligned_coord_feats: Tensor of shape [num_graph_nodes, 3].\n",
        "        max_scalar_len, max_vector_len: Maximum lengths used for scalar and vector features.\n",
        "    \"\"\"\n",
        "    aligned_scalar_feats = []\n",
        "    aligned_vector_feats = []\n",
        "    aligned_coord_feats = []\n",
        "\n",
        "    # Calculate max_scalar_len and max_vector_len dynamically if not provided\n",
        "    if max_scalar_len is None:\n",
        "        max_scalar_len = max([v.size(0) for v in scalar_feats_dict.values()]) if scalar_feats_dict else 0\n",
        "        print(f\"Computed max_scalar_len: {max_scalar_len}\")\n",
        "\n",
        "    if max_vector_len is None:\n",
        "        max_vector_len = max([v.size(0) for v in vector_feats_dict.values()]) if vector_feats_dict else 0\n",
        "        print(f\"Computed max_vector_len: {max_vector_len}\")\n",
        "\n",
        "    for protein in graph_nodes:\n",
        "        if protein in scalar_feats_dict:\n",
        "            # Scalar features: truncate or pad\n",
        "            scalar_feat = scalar_feats_dict[protein]\n",
        "            if scalar_feat.size(0) > max_scalar_len:\n",
        "                scalar_feat = scalar_feat[:max_scalar_len]  # Truncate\n",
        "            elif scalar_feat.size(0) < max_scalar_len:\n",
        "                padding = torch.zeros((max_scalar_len - scalar_feat.size(0), scalar_feat.size(1)))\n",
        "                scalar_feat = torch.cat([scalar_feat, padding], dim=0)  # Pad\n",
        "            aligned_scalar_feats.append(scalar_feat)\n",
        "\n",
        "            # Vector features: truncate or pad\n",
        "            vector_feat = vector_feats_dict[protein]\n",
        "            if vector_feat.size(0) > max_vector_len:\n",
        "                vector_feat = vector_feat[:max_vector_len]  # Truncate\n",
        "            elif vector_feat.size(0) < max_vector_len:\n",
        "                padding = torch.zeros((max_vector_len - vector_feat.size(0), vector_feat.size(1)))\n",
        "                vector_feat = torch.cat([vector_feat, padding], dim=0)  # Pad\n",
        "            aligned_vector_feats.append(vector_feat)\n",
        "\n",
        "            # Coordinate features: use aggregated centroid\n",
        "            coord_feat = coord_feats_dict[protein].mean(dim=0)  # Aggregate to single coordinate\n",
        "            aligned_coord_feats.append(coord_feat)\n",
        "        else:\n",
        "            print(f\"Protein: {protein} missing in features. Appending zeros.\")\n",
        "            # Handle missing proteins\n",
        "            aligned_scalar_feats.append(torch.zeros((max_scalar_len, 20)))  # Placeholder for scalar features\n",
        "            aligned_vector_feats.append(torch.zeros((max_vector_len, 3)))  # Placeholder for vector features\n",
        "            aligned_coord_feats.append(torch.zeros(3))  # Placeholder for aggregated coordinate\n",
        "\n",
        "    # Convert lists of tensors into batched tensors\n",
        "    aligned_scalar_feats = torch.stack(aligned_scalar_feats)  # Shape: [num_graph_nodes, max_scalar_len, 20]\n",
        "    aligned_vector_feats = torch.stack(aligned_vector_feats)  # Shape: [num_graph_nodes, max_vector_len, 3]\n",
        "    aligned_coord_feats = torch.stack(aligned_coord_feats)  # Shape: [num_graph_nodes, 3]\n",
        "\n",
        "    return aligned_scalar_feats, aligned_vector_feats, aligned_coord_feats, max_scalar_len, max_vector_len\n",
        "\n",
        "# Adjust `max_vector_len` as necessary based on the average size of vector features in your dataset.\n",
        "aligned_scalar_feats, aligned_vector_feats, aligned_coord_feats, max_scalar_len, max_vector_len = align_features_to_graph(\n",
        "    graph_nodes=proteins_with_labels,\n",
        "    scalar_feats_dict=scalar_feats_dict,\n",
        "    vector_feats_dict=vector_feats_dict,\n",
        "    coord_feats_dict=coord_feats_dict\n",
        ")"
      ],
      "metadata": {
        "id": "nxlZHSPNBbmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPH0ePXmBtOH"
      },
      "outputs": [],
      "source": [
        "# Save the features\n",
        "os.makedirs(f\"{BASE_DIR}/saved_features\", exist_ok=True)\n",
        "\n",
        "torch.save(aligned_scalar_feats, os.path.join(f\"{BASE_DIR}/saved_features\", \"aligned_scalar_feats.pt\"))\n",
        "torch.save(aligned_vector_feats, os.path.join(f\"{BASE_DIR}/saved_features\", \"aligned_vector_feats.pt\"))\n",
        "torch.save(aligned_coord_feats, os.path.join(f\"{BASE_DIR}/saved_features\", \"aligned_coord_feats.pt\"))\n",
        "\n",
        "print(f\"Features saved to {BASE_DIR}/saved_features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip92d6sgD2t9"
      },
      "outputs": [],
      "source": [
        "# Load the features\n",
        "aligned_scalar_feats = torch.load(os.path.join(f\"{BASE_DIR}/saved_features\", \"aligned_scalar_feats.pt\"))\n",
        "aligned_vector_feats = torch.load(os.path.join(f\"{BASE_DIR}/saved_features\", \"aligned_vector_feats.pt\"))\n",
        "aligned_coord_feats = torch.load(os.path.join(f\"{BASE_DIR}/saved_features\", \"aligned_coord_feats.pt\"))\n",
        "\n",
        "print(\"Features loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the graph\n",
        "graph = dgl.graph((filtered_edge_index[0], filtered_edge_index[1]))\n",
        "\n",
        "# assign features to the graph\n",
        "graph.ndata['scalar_feats'] = aligned_scalar_feats.mean(dim=1)\n",
        "graph.ndata['vector_feats'] = aligned_vector_feats\n",
        "graph.ndata['coords'] = aligned_coord_feats\n",
        "graph.ndata['esm'] = filtered_esm_embeddings"
      ],
      "metadata": {
        "id": "KvLwB-wx22aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdD3-ozKwJcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV0DoVSg4FMk"
      },
      "source": [
        "## GVP module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2Q9lKNc_1fM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "from typing import List, Tuple, Union, Dict\n",
        "import math\n",
        "\n",
        "# helper functions\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):\n",
        "    '''\n",
        "    L2 norm of tensor clamped above a minimum value `eps`.\n",
        "\n",
        "    :param sqrt: if `False`, returns the square of the L2 norm\n",
        "    '''\n",
        "    out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps)\n",
        "    return torch.sqrt(out) if sqrt else out\n",
        "\n",
        "# the classes GVP, GVPDropout, and GVPLayerNorm are taken from lucidrains' geometric-vector-perceptron repository\n",
        "# https://github.com/lucidrains/geometric-vector-perceptron/tree/main\n",
        "# some adaptations have been made to these classes to make them more consistent with the original GVP paper/implementation\n",
        "# specifically, using _norm_no_nan instead of torch's built in norm function, and the weight intialiation scheme for Wh and Wu\n",
        "\n",
        "def _rbf(D, D_min=0., D_max=20., D_count=16):\n",
        "    '''\n",
        "    From https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "    Returns an RBF embedding of `torch.Tensor` `D` along a new axis=-1.\n",
        "    That is, if `D` has shape [...dims], then the returned tensor will have\n",
        "    shape [...dims, D_count].\n",
        "    '''\n",
        "    device = D.device\n",
        "    D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "    D_mu = D_mu.view([1, -1])\n",
        "    D_sigma = (D_max - D_min) / D_count\n",
        "    D_expand = torch.unsqueeze(D, -1)\n",
        "\n",
        "    RBF = torch.exp(-((D_expand - D_mu) / D_sigma) ** 2)\n",
        "    return RBF\n",
        "\n",
        "class GVP(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim_vectors_in,\n",
        "        dim_vectors_out,\n",
        "        dim_feats_in,\n",
        "        dim_feats_out,\n",
        "        n_cp_feats = 0, # number of cross-product features added to hidden vector features\n",
        "        hidden_vectors = None,\n",
        "        feats_activation = nn.SiLU(),\n",
        "        vectors_activation = nn.Sigmoid(),\n",
        "        vector_gating = True,\n",
        "        xavier_init = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dim_vectors_in = dim_vectors_in\n",
        "        self.dim_feats_in = dim_feats_in\n",
        "\n",
        "        # debug\n",
        "        # print(f\"GVP initialized with dim_feats_in: {self.dim_feats_in}\")\n",
        "\n",
        "        self.n_cp_feats = n_cp_feats\n",
        "\n",
        "        self.dim_vectors_out = dim_vectors_out\n",
        "        dim_h = max(dim_vectors_in, dim_vectors_out) if hidden_vectors is None else hidden_vectors\n",
        "\n",
        "        # create Wh matrix\n",
        "        wh_k = 1/math.sqrt(dim_vectors_in)\n",
        "        self.Wh = torch.zeros(dim_vectors_in, dim_h, dtype=torch.float32).uniform_(-wh_k, wh_k)\n",
        "        self.Wh = nn.Parameter(self.Wh)\n",
        "\n",
        "        # create Wcp matrix if we are using cross-product features\n",
        "        if n_cp_feats > 0:\n",
        "            wcp_k = 1/math.sqrt(dim_vectors_in)\n",
        "            self.Wcp = torch.zeros(dim_vectors_in, n_cp_feats*2, dtype=torch.float32).uniform_(-wcp_k, wcp_k)\n",
        "            self.Wcp = nn.Parameter(self.Wcp)\n",
        "\n",
        "\n",
        "\n",
        "        # create Wu matrix\n",
        "        if n_cp_feats > 0: # the number of vector features going into Wu is increased by n_cp_feats if we are using cross-product features\n",
        "            wu_in_dim = dim_h + n_cp_feats\n",
        "        else:\n",
        "            wu_in_dim = dim_h\n",
        "        wu_k = 1/math.sqrt(wu_in_dim)\n",
        "        self.Wu = torch.zeros(wu_in_dim, dim_vectors_out, dtype=torch.float32).uniform_(-wu_k, wu_k)\n",
        "        self.Wu = nn.Parameter(self.Wu)\n",
        "\n",
        "        self.vectors_activation = vectors_activation\n",
        "\n",
        "        self.to_feats_out = nn.Sequential(\n",
        "            nn.Linear(dim_h + n_cp_feats + dim_feats_in, dim_feats_out),\n",
        "            feats_activation\n",
        "        )\n",
        "\n",
        "        # branching logic to use old GVP, or GVP with vector gating\n",
        "        if vector_gating:\n",
        "            self.scalar_to_vector_gates = nn.Linear(dim_feats_out, dim_vectors_out)\n",
        "            if xavier_init:\n",
        "                nn.init.xavier_uniform_(self.scalar_to_vector_gates.weight, gain=1)\n",
        "                nn.init.constant_(self.scalar_to_vector_gates.bias, 0)\n",
        "        else:\n",
        "            self.scalar_to_vector_gates = None\n",
        "\n",
        "        # self.scalar_to_vector_gates = nn.Linear(dim_feats_out, dim_vectors_out) if vector_gating else None\n",
        "\n",
        "    def forward(self, data):\n",
        "        feats, vectors = data\n",
        "\n",
        "        # debug\n",
        "        # print(f\"feats shape: {feats.shape}\")\n",
        "        # print(f\"vectors shape: {vectors.shape}\")\n",
        "\n",
        "        b, n, _, v, c  = *feats.shape, *vectors.shape\n",
        "\n",
        "        # feats has shape (batch_size, n_feats)\n",
        "        # vectors has shape (batch_size, n_vectors, 3)\n",
        "\n",
        "        assert c == 3 and v == self.dim_vectors_in, 'vectors have wrong dimensions'\n",
        "\n",
        "        # debug\n",
        "        # print(f\"n (scalar feature size): {n}\")\n",
        "        # print(f\"self.dim_feats_in: {self.dim_feats_in}\")\n",
        "        assert n == self.dim_feats_in, 'scalar features have wrong dimensions'\n",
        "\n",
        "        Vh = einsum('b v c, v h -> b h c', vectors, self.Wh) # has shape (batch_size, dim_h, 3)\n",
        "\n",
        "        # if we are including cross-product features, compute them here\n",
        "        if self.n_cp_feats > 0:\n",
        "            # convert dim_vectors_in vectors to n_cp_feats*2 vectors\n",
        "            Vcp = einsum('b v c, v p -> b p c', vectors, self.Wcp) # has shape (batch_size, n_cp_feats*2, 3)\n",
        "            # split the n_cp_feats*2 vectors into two sets of n_cp_feats vectors\n",
        "            cp_src, cp_dst = torch.split(Vcp, self.n_cp_feats, dim=1) # each has shape (batch_size, n_cp_feats, 3)\n",
        "            # take the cross product of the two sets of vectors\n",
        "            cp = torch.linalg.cross(cp_src, cp_dst, dim=-1) # has shape (batch_size, n_cp_feats, 3)\n",
        "\n",
        "            # add the cross product features to the hidden vector features\n",
        "            Vh = torch.cat((Vh, cp), dim=1) # has shape (batch_size, dim_h + n_cp_feats, 3)\n",
        "\n",
        "        Vu = einsum('b h c, h u -> b u c', Vh, self.Wu) # has shape (batch_size, dim_vectors_out, 3)\n",
        "\n",
        "        sh = _norm_no_nan(Vh)\n",
        "\n",
        "        s = torch.cat((feats, sh), dim = 1)\n",
        "\n",
        "        feats_out = self.to_feats_out(s)\n",
        "\n",
        "        if exists(self.scalar_to_vector_gates):\n",
        "            gating = self.scalar_to_vector_gates(feats_out)\n",
        "            gating = gating.unsqueeze(dim = -1)\n",
        "        else:\n",
        "            gating = _norm_no_nan(Vu)\n",
        "\n",
        "        vectors_out = self.vectors_activation(gating) * Vu\n",
        "\n",
        "        # if torch.isnan(feats_out).any() or torch.isnan(vectors_out).any():\n",
        "        #     raise ValueError(\"NaNs in GVP forward pass\")\n",
        "\n",
        "        return (feats_out, vectors_out)\n",
        "\n",
        "class _VDropout(nn.Module):\n",
        "    '''\n",
        "    Vector channel dropout where the elements of each\n",
        "    vector channel are dropped together.\n",
        "    '''\n",
        "    def __init__(self, drop_rate):\n",
        "        super(_VDropout, self).__init__()\n",
        "        self.drop_rate = drop_rate\n",
        "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: `torch.Tensor` corresponding to vector channels\n",
        "        '''\n",
        "        device = self.dummy_param.device\n",
        "        if not self.training:\n",
        "            return x\n",
        "        mask = torch.bernoulli(\n",
        "            (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device)\n",
        "        ).unsqueeze(-1)\n",
        "        x = mask * x / (1 - self.drop_rate)\n",
        "        return x\n",
        "\n",
        "class GVPDropout(nn.Module):\n",
        "    \"\"\" Separate dropout for scalars and vectors. \"\"\"\n",
        "    def __init__(self, rate):\n",
        "        super().__init__()\n",
        "        self.vector_dropout = _VDropout(rate)\n",
        "        self.feat_dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, feats, vectors):\n",
        "        return self.feat_dropout(feats), self.vector_dropout(vectors)\n",
        "\n",
        "\n",
        "class GVPLayerNorm(nn.Module):\n",
        "    \"\"\" Normal layer norm for scalars, nontrainable norm for vectors. \"\"\"\n",
        "    def __init__(self, feats_h_size, eps = 1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.feat_norm = nn.LayerNorm(feats_h_size)\n",
        "\n",
        "    def forward(self, feats, vectors):\n",
        "\n",
        "        normed_feats = self.feat_norm(feats)\n",
        "\n",
        "        vn = _norm_no_nan(vectors, axis=-1, keepdims=True, sqrt=False)\n",
        "        vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True) + self.eps ) + self.eps\n",
        "        normed_vectors = vectors / vn\n",
        "        return normed_feats, normed_vectors\n",
        "\n",
        "\n",
        "\n",
        "class GVPConv(nn.Module):\n",
        "\n",
        "    \"\"\"GVP graph convolution on a homogenous graph.\"\"\"\n",
        "\n",
        "    def __init__(self, scalar_size: int = 128, vector_size: int = 16, n_cp_feats: int = 0,\n",
        "                  scalar_activation=nn.SiLU, vector_activation=nn.Sigmoid,\n",
        "                  n_message_gvps: int = 1, n_update_gvps: int = 1,\n",
        "                  use_dst_feats: bool = False, rbf_dmax: float = 20, rbf_dim: int = 16,\n",
        "                  edge_feat_size: int = 0, coords_range=10, message_norm: Union[float, str] = 10, dropout: float = 0.0,):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # self.edge_type = edge_type\n",
        "        # self.src_ntype = edge_type[0]\n",
        "        # self.dst_ntype = edge_type[2]\n",
        "        self.scalar_size = scalar_size\n",
        "        self.vector_size = vector_size\n",
        "        self.n_cp_feats = n_cp_feats\n",
        "        self.scalar_activation = scalar_activation\n",
        "        self.vector_activation = vector_activation\n",
        "        self.n_message_gvps = n_message_gvps\n",
        "        self.n_update_gvps = n_update_gvps\n",
        "        self.edge_feat_size = edge_feat_size\n",
        "        self.use_dst_feats = use_dst_feats\n",
        "        self.rbf_dmax = rbf_dmax\n",
        "        self.rbf_dim = rbf_dim\n",
        "        self.dropout_rate = dropout\n",
        "        self.message_norm = message_norm\n",
        "\n",
        "        # create message passing function\n",
        "        message_gvps = []\n",
        "        for i in range(n_message_gvps):\n",
        "\n",
        "            dim_vectors_in = vector_size\n",
        "            dim_feats_in = scalar_size\n",
        "\n",
        "            # on the first layer, there is an extra edge vector for the displacement vector between the two node positions\n",
        "            if i == 0:\n",
        "                dim_vectors_in += 1\n",
        "                dim_feats_in += rbf_dim + edge_feat_size\n",
        "\n",
        "            # if this is the first layer and we are using destination node features to compute messages, add them to the input dimensions\n",
        "            if use_dst_feats and i == 0:\n",
        "                dim_vectors_in += vector_size\n",
        "                dim_feats_in += scalar_size\n",
        "\n",
        "            message_gvps.append(\n",
        "                GVP(dim_vectors_in=dim_vectors_in,\n",
        "                    dim_vectors_out=vector_size,\n",
        "                    n_cp_feats=n_cp_feats,\n",
        "                    dim_feats_in=dim_feats_in,\n",
        "                    dim_feats_out=scalar_size,\n",
        "                    feats_activation=scalar_activation(),\n",
        "                    vectors_activation=vector_activation(),\n",
        "                    vector_gating=True)\n",
        "            )\n",
        "        self.edge_message = nn.Sequential(*message_gvps)\n",
        "\n",
        "        # create update function\n",
        "        update_gvps = []\n",
        "        for i in range(n_update_gvps):\n",
        "            update_gvps.append(\n",
        "                GVP(dim_vectors_in=vector_size,\n",
        "                    dim_vectors_out=vector_size,\n",
        "                    n_cp_feats=n_cp_feats,\n",
        "                    dim_feats_in=scalar_size,\n",
        "                    dim_feats_out=scalar_size,\n",
        "                    feats_activation=scalar_activation(),\n",
        "                    vectors_activation=vector_activation(),\n",
        "                    vector_gating=True)\n",
        "            )\n",
        "        self.node_update = nn.Sequential(*update_gvps)\n",
        "\n",
        "        self.dropout = GVPDropout(self.dropout_rate)\n",
        "        self.message_layer_norm = GVPLayerNorm(self.scalar_size)\n",
        "        self.update_layer_norm = GVPLayerNorm(self.scalar_size)\n",
        "\n",
        "        if isinstance(self.message_norm, str) and self.message_norm not in ['mean', 'sum']:\n",
        "            raise ValueError(f\"message_norm must be either 'mean', 'sum', or a number, got {self.message_norm}\")\n",
        "        else:\n",
        "            assert isinstance(self.message_norm, (float, int)), \"message_norm must be either 'mean', 'sum', or a number\"\n",
        "\n",
        "        if self.message_norm == 'mean':\n",
        "            self.agg_func = fn.mean\n",
        "        else:\n",
        "            self.agg_func = fn.sum\n",
        "\n",
        "    def forward(self, g: dgl.DGLGraph,\n",
        "                scalar_feats: torch.Tensor,\n",
        "                coord_feats: torch.Tensor,\n",
        "                vec_feats: torch.Tensor,\n",
        "                edge_feats: torch.Tensor = None,\n",
        "                x_diff: torch.Tensor = None,\n",
        "                d: torch.Tensor = None):\n",
        "        # vec_feat has shape (n_nodes, n_vectors, 3)\n",
        "\n",
        "        with g.local_scope():\n",
        "\n",
        "            g.ndata['h'] = scalar_feats\n",
        "            g.ndata['x'] = coord_feats\n",
        "            g.ndata['v'] = vec_feats\n",
        "\n",
        "            if x_diff is not None and d is not None:\n",
        "                g.edata['x_diff'] = x_diff\n",
        "                g.edata['d'] = d\n",
        "\n",
        "            # edge feature\n",
        "            if self.edge_feat_size > 0:\n",
        "                assert edge_feats is not None, \"Edge features must be provided.\"\n",
        "                g.edata[\"a\"] = edge_feats\n",
        "\n",
        "\n",
        "\n",
        "            # normalize x_diff and compute rbf embedding of edge distance\n",
        "            # dij = torch.norm(g.edges[self.edge_type].data['x_diff'], dim=-1, keepdim=True)\n",
        "            if 'x_diff' not in g.edata:\n",
        "                # get vectors between node positions\n",
        "                g.apply_edges(fn.u_sub_v(\"x\", \"x\", \"x_diff\"))\n",
        "                dij = _norm_no_nan(g.edata['x_diff'], keepdims=True) + 1e-8\n",
        "                g.edata['x_diff'] = g.edata['x_diff'] / dij\n",
        "                g.edata['d'] = _rbf(dij.squeeze(1), D_max=self.rbf_dmax, D_count=self.rbf_dim)\n",
        "\n",
        "            # compute messages on every edge\n",
        "            g.apply_edges(self.message)\n",
        "\n",
        "            # aggregate messages from every edge\n",
        "            g.update_all(fn.copy_e(\"scalar_msg\", \"m\"), self.agg_func(\"m\", \"scalar_msg\"))\n",
        "            g.update_all(fn.copy_e(\"vec_msg\", \"m\"), self.agg_func(\"m\", \"vec_msg\"))\n",
        "\n",
        "            # get aggregated scalar and vector messages\n",
        "            if isinstance(self.message_norm, str):\n",
        "                z = 1\n",
        "            else:\n",
        "                z = self.message_norm\n",
        "\n",
        "            scalar_msg = g.ndata[\"scalar_msg\"] / z\n",
        "            vec_msg = g.ndata[\"vec_msg\"] / z\n",
        "\n",
        "            # dropout scalar and vector messages\n",
        "            scalar_msg, vec_msg = self.dropout(scalar_msg, vec_msg)\n",
        "\n",
        "            # update scalar and vector features, apply layernorm\n",
        "            scalar_feat = g.ndata['h'] + scalar_msg\n",
        "            vec_feat = g.ndata['v'] + vec_msg\n",
        "            scalar_feat, vec_feat = self.message_layer_norm(scalar_feat, vec_feat)\n",
        "\n",
        "            # apply node update function, apply dropout to residuals, apply layernorm\n",
        "            scalar_residual, vec_residual = self.node_update((scalar_feat, vec_feat))\n",
        "            scalar_residual, vec_residual = self.dropout(scalar_residual, vec_residual)\n",
        "            scalar_feat = scalar_feat + scalar_residual\n",
        "            vec_feat = vec_feat + vec_residual\n",
        "            scalar_feat, vec_feat = self.update_layer_norm(scalar_feat, vec_feat)\n",
        "\n",
        "        return scalar_feat, vec_feat\n",
        "\n",
        "    def message(self, edges):\n",
        "\n",
        "        # concatenate x_diff and v on every edge to produce vector features\n",
        "        vec_feats = [ edges.data[\"x_diff\"].unsqueeze(1), edges.src[\"v\"] ]\n",
        "        if self.use_dst_feats:\n",
        "            vec_feats.append(edges.dst[\"v\"])\n",
        "        vec_feats = torch.cat(vec_feats, dim=1)\n",
        "\n",
        "        # Before concatenation\n",
        "        # create scalar features\n",
        "        scalar_feats = [ edges.src['h'], edges.data['d'] ]\n",
        "        if self.edge_feat_size > 0:\n",
        "            scalar_feats.append(edges.data['a'])\n",
        "\n",
        "        if self.use_dst_feats:\n",
        "            scalar_feats.append(edges.dst['h'])\n",
        "\n",
        "        scalar_feats = torch.cat(scalar_feats, dim=1)\n",
        "\n",
        "        # print(f\"scalar_feats shape after concatenation: {scalar_feats.shape}\")\n",
        "        # print(f\"Expected dim_feats_in: {self.edge_message[0].dim_feats_in}\")\n",
        "\n",
        "        scalar_message, vector_message = self.edge_message((scalar_feats, vec_feats))\n",
        "\n",
        "        return {\"scalar_msg\": scalar_message, \"vec_msg\": vector_message}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qKv-nbI4KNC"
      },
      "source": [
        "## define our own GVP-GCN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-MxAkJC4Nfr"
      },
      "outputs": [],
      "source": [
        "class GVP_GCN(nn.Module):\n",
        "    def __init__(self, scalar_input_dim, vector_input_dim, scalar_hidden_dim, vector_hidden_dim, output_dim):\n",
        "        super(GVP_GCN, self).__init__()\n",
        "        # Single GVPConv layer\n",
        "        self.gvp_conv = GVPConv(\n",
        "            scalar_size=scalar_input_dim,\n",
        "            vector_size=vector_input_dim,\n",
        "            scalar_activation=nn.ReLU,\n",
        "            vector_activation=nn.ReLU,\n",
        "            n_message_gvps=2,\n",
        "            n_update_gvps=2,\n",
        "            rbf_dmax=20,  # Example value for radial basis function\n",
        "            rbf_dim=8,   # Example value for radial basis function dimensions\n",
        "            dropout=0.1   # Example dropout rate\n",
        "        )\n",
        "        self.fc = nn.Linear(scalar_input_dim, output_dim)  # Final prediction layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, graph, scalar_feats, coords, vector_feats):\n",
        "        # Update graph with node features\n",
        "        graph.ndata['scalar_feats'] = scalar_feats\n",
        "        graph.ndata['vector_feats'] = vector_feats\n",
        "        graph.ndata['coords'] = coords\n",
        "\n",
        "        # Apply the GVPConv layer\n",
        "        scalar_feats, vector_feats = self.gvp_conv(graph, scalar_feats, coords, vector_feats)\n",
        "\n",
        "        # Apply final linear layer for prediction\n",
        "        out = self.fc(scalar_feats)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mini-batch training"
      ],
      "metadata": {
        "id": "tx5eyFN9xYd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_nids = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
        "val_nids = torch.nonzero(val_mask, as_tuple=False).squeeze()\n",
        "\n",
        "graph = graph.to(device)\n",
        "data_y = data_y.to(device)\n"
      ],
      "metadata": {
        "id": "BjIE-H2cxwjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class GVP_GCN(nn.Module):\n",
        "    def __init__(self, scalar_input_dim, vector_input_dim, scalar_hidden_dim, vector_hidden_dim, output_dim):\n",
        "        super(GVP_GCN, self).__init__()\n",
        "        self.gvp_conv = GVPConv(\n",
        "            scalar_size=scalar_input_dim,\n",
        "            vector_size=vector_input_dim,\n",
        "            scalar_activation=nn.ReLU,\n",
        "            vector_activation=nn.ReLU,\n",
        "            n_message_gvps=2,\n",
        "            n_update_gvps=2,\n",
        "            rbf_dmax=20,\n",
        "            rbf_dim=8,\n",
        "            dropout=0.1\n",
        "        )\n",
        "        self.fc = nn.Linear(scalar_input_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, graph, scalar_feats, coords, vector_feats):\n",
        "        scalar_feats, vector_feats = self.gvp_conv(graph, scalar_feats, coords, vector_feats)\n",
        "        out = self.fc(scalar_feats)\n",
        "        return out"
      ],
      "metadata": {
        "id": "PhRfGYf5Mg7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Custom Dataset for Node IDs\n",
        "class NodeDataset(Dataset):\n",
        "    def __init__(self, node_ids):\n",
        "        self.node_ids = node_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.node_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.node_ids[idx]\n",
        "\n",
        "# Define training function\n",
        "def train_epoch(model, data_loader, graph, data_y, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
        "        # Ensure the batch is on the same device as the graph\n",
        "        batch = batch.to(graph.device)\n",
        "\n",
        "        # Sample a mini-batch subgraph\n",
        "        mini_batch_graph = dgl.node_subgraph(graph, batch)\n",
        "        mini_batch_graph = mini_batch_graph.to(device)  # Move subgraph to the device\n",
        "\n",
        "        # Extract features and labels for the mini-batch\n",
        "        scalar_feats = mini_batch_graph.ndata['scalar_feats'].to(device)\n",
        "        coords = mini_batch_graph.ndata['coords'].to(device)\n",
        "        vector_feats = mini_batch_graph.ndata['vector_feats'].to(device)\n",
        "        labels = data_y[mini_batch_graph.ndata[dgl.NID].to('cpu')].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(mini_batch_graph, scalar_feats, coords, vector_feats)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(batch)\n",
        "        count += len(batch)\n",
        "\n",
        "    return total_loss / count\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader, graph, data_y, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for batch in tqdm(data_loader, desc=\"Evaluation\"):\n",
        "        # Ensure the batch is on the same device as the graph\n",
        "        batch = batch.to(graph.device)\n",
        "\n",
        "        # Sample a mini-batch subgraph\n",
        "        mini_batch_graph = dgl.node_subgraph(graph, batch)\n",
        "        mini_batch_graph = mini_batch_graph.to(device)  # Move subgraph to the device\n",
        "\n",
        "        # Extract features and labels for the mini-batch\n",
        "        scalar_feats = mini_batch_graph.ndata['scalar_feats'].to(device)\n",
        "        coords = mini_batch_graph.ndata['coords'].to(device)\n",
        "        vector_feats = mini_batch_graph.ndata['vector_feats'].to(device)\n",
        "        labels = data_y[mini_batch_graph.ndata[dgl.NID].to('cpu')].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(mini_batch_graph, scalar_feats, coords, vector_feats)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        total_loss += loss.item() * len(batch)\n",
        "        count += len(batch)\n",
        "\n",
        "    return total_loss / count\n",
        "\n",
        "# Create datasets and data loaders\n",
        "train_nids = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
        "val_nids = torch.nonzero(val_mask, as_tuple=False).squeeze()\n",
        "\n",
        "train_dataset = NodeDataset(train_nids)\n",
        "val_dataset = NodeDataset(val_nids)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "# Model and optimizer setup\n",
        "scalar_input_dim = graph.ndata['scalar_feats'].shape[1]\n",
        "vector_input_dim = graph.ndata['vector_feats'].shape[1]\n",
        "output_dim = data_y.shape[1]"
      ],
      "metadata": {
        "id": "t0W-F0R9xwlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GVP_GCN(scalar_input_dim, vector_input_dim, 8, 4, output_dim).to(device)\n",
        "\n",
        "# Calculate pos_weight\n",
        "num_samples = train_mask.shape[0]  # Total number of training samples\n",
        "num_positive_per_class = train_mask.sum(dim=0).float()  # Number of positive samples per class\n",
        "\n",
        "# Avoid division by zero by replacing zero counts with a very small number\n",
        "num_positive_per_class[num_positive_per_class == 0] = float('inf')  # To avoid division by zero\n",
        "pos_weight = num_samples / (2 * num_positive_per_class)\n",
        "\n",
        "# Replace inf values with 0.0 or any default value you prefer\n",
        "pos_weight[torch.isinf(pos_weight)] = 0.0\n",
        "\n",
        "# Pass pos_weight to BCEWithLogitsLoss\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(model, train_loader, graph, data_y, criterion, optimizer)\n",
        "    val_loss = evaluate(model, val_loader, graph, data_y, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "dSWOFZ-gA8OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "def compute_metrics(predictions, labels, thresholds=np.linspace(0, 1, 101)):\n",
        "    \"\"\"\n",
        "    predictions: numpy array of shape (num_proteins, num_terms), predicted probabilities\n",
        "    labels: numpy array of shape (num_proteins, num_terms)\n",
        "    thresholds: array-like, list of thresholds to evaluate for Fmax\n",
        "\n",
        "    Returns:\n",
        "        fmax: Average maximum F1 score across proteins\n",
        "        aupr: Average area under precision-recall curve across GO terms\n",
        "        f1_max_scores: numpy array of fmax_values\n",
        "        aupr_scores: numpy array of aupr values\n",
        "    \"\"\"\n",
        "    num_proteins, num_terms = labels.shape\n",
        "\n",
        "    f1_max_scores = []\n",
        "    for i in range(num_proteins):\n",
        "        protein_preds = predictions[i]\n",
        "        protein_labels = labels[i]\n",
        "\n",
        "        max_f1 = 0\n",
        "        for t in thresholds:\n",
        "            binary_preds = (protein_preds >= t).astype(int)\n",
        "            tp = np.sum((binary_preds == 1) & (protein_labels == 1))\n",
        "            fp = np.sum((binary_preds == 1) & (protein_labels == 0))\n",
        "            fn = np.sum((binary_preds == 0) & (protein_labels == 1))\n",
        "\n",
        "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
        "            max_f1 = max(max_f1, f1)\n",
        "\n",
        "        f1_max_scores.append(max_f1)\n",
        "\n",
        "    fmax = np.mean(f1_max_scores)\n",
        "\n",
        "    aupr_scores = []\n",
        "    for j in range(num_terms):\n",
        "        term_preds = predictions[:, j]\n",
        "        term_labels = labels[:, j]\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(term_labels, term_preds)\n",
        "        aupr = auc(recall, precision)\n",
        "        aupr_scores.append(aupr)\n",
        "\n",
        "    aupr = np.mean(aupr_scores)\n",
        "\n",
        "    return fmax, aupr, f1_max_scores, aupr_scores"
      ],
      "metadata": {
        "id": "8IljnR25xwqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_on_test_set(model, test_loader, graph, data_y):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set using Fmax and AUPR metrics.\n",
        "\n",
        "    Parameters:\n",
        "        model: Trained GVP-GCN model.\n",
        "        test_loader: DataLoader for the test set.\n",
        "        graph: Original DGL graph.\n",
        "        data_y: Ground-truth labels for all nodes.\n",
        "\n",
        "    Returns:\n",
        "        fmax: Average maximum F1 score across proteins.\n",
        "        aupr: Average area under precision-recall curve across GO terms.\n",
        "        f1_max_scores: numpy array of Fmax values.\n",
        "        aupr_scores: numpy array of AUPR values.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n",
        "        # Ensure batch is on the same device as the graph\n",
        "        batch = batch.to(graph.device)\n",
        "\n",
        "        # Sample a mini-batch subgraph\n",
        "        mini_batch_graph = dgl.node_subgraph(graph, batch)\n",
        "        mini_batch_graph = mini_batch_graph.to(graph.device)\n",
        "\n",
        "        # Extract features for the mini-batch\n",
        "        scalar_feats = mini_batch_graph.ndata['scalar_feats'].to(graph.device)\n",
        "        coords = mini_batch_graph.ndata['coords'].to(graph.device)\n",
        "        vector_feats = mini_batch_graph.ndata['vector_feats'].to(graph.device)\n",
        "\n",
        "        # Predict outputs\n",
        "        outputs = torch.sigmoid(model(mini_batch_graph, scalar_feats, coords, vector_feats)).cpu().numpy()\n",
        "\n",
        "        # Extract labels for the mini-batch\n",
        "        batch_labels = data_y[mini_batch_graph.ndata[dgl.NID].to('cpu')].to('cpu').numpy()\n",
        "\n",
        "        predictions.append(outputs)\n",
        "        labels.append(batch_labels)\n",
        "\n",
        "    # Concatenate all predictions and labels\n",
        "    predictions = np.vstack(predictions)\n",
        "    labels = np.vstack(labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    fmax, aupr, f1_max_scores, aupr_scores = compute_metrics(predictions, labels)\n",
        "\n",
        "    print(f\"Test Set Evaluation:\")\n",
        "    print(f\"Fmax: {fmax:.4f}, AUPR: {aupr:.4f}\")\n",
        "    return fmax, aupr, f1_max_scores, aupr_scores"
      ],
      "metadata": {
        "id": "MMJBZRiw9SyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "# Get test node IDs\n",
        "test_nids = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
        "\n",
        "# Create a dataset and data loader for the test set\n",
        "test_dataset = NodeDataset(test_nids)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)  # No need to shuffle the test set\n",
        "\n",
        "fmax, aupr, f1_max_scores, aupr_scores = evaluate_on_test_set(\n",
        "    model, test_loader, graph, data_y\n",
        ")"
      ],
      "metadata": {
        "id": "-W2Uc62j9Tfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyuOEjOO9kna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GVP + ESM\n"
      ],
      "metadata": {
        "id": "6w8tNWHitpsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GVP_ESM_GCN(nn.Module):\n",
        "    def __init__(self, scalar_input_dim, vector_input_dim, scalar_hidden_dim, vector_hidden_dim, esm_embedding_dim, output_dim):\n",
        "        super(GVP_ESM_GCN, self).__init__()\n",
        "        # GVP layer\n",
        "        self.gvp_conv = GVPConv(\n",
        "            scalar_size=scalar_input_dim,\n",
        "            vector_size=vector_input_dim,\n",
        "            scalar_activation=nn.ReLU,\n",
        "            vector_activation=nn.ReLU,\n",
        "            n_message_gvps=2,\n",
        "            n_update_gvps=2,\n",
        "            rbf_dmax=20,\n",
        "            rbf_dim=8,\n",
        "            dropout=0.1\n",
        "        )\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layer for concatenated features\n",
        "        concatenated_dim = scalar_input_dim + esm_embedding_dim\n",
        "        self.fc = nn.Linear(concatenated_dim, output_dim)\n",
        "\n",
        "    def forward(self, graph, scalar_feats, coords, vector_feats, esm_embeddings):\n",
        "        # GVP processing\n",
        "        scalar_feats, vector_feats = self.gvp_conv(graph, scalar_feats, coords, vector_feats)\n",
        "\n",
        "        # Concatenate GVP scalar output with ESM embeddings\n",
        "        combined_feats = torch.cat((scalar_feats, esm_embeddings), dim=1)\n",
        "\n",
        "        # Apply dropout and final fully connected layer\n",
        "        combined_feats = self.dropout(combined_feats)\n",
        "        out = self.fc(combined_feats)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Cfi01BE8tu3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load ESM embeddings\n",
        "esm_embeddings = torch.load(f\"{BASE_DIR}/protein_esm_embeddings.pt\")\n",
        "filtered_esm_embeddings = torch.stack([esm_embeddings[protein_to_idx[protein]]\n",
        "                                       for protein in proteins_with_labels])"
      ],
      "metadata": {
        "id": "aghhSWWmuG47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training function\n",
        "def train_with_esm_epoch(model, data_loader, graph, data_y, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
        "        # Ensure the batch is on the same device as the graph\n",
        "        batch = batch.to(graph.device)\n",
        "\n",
        "        # Sample a mini-batch subgraph\n",
        "        mini_batch_graph = dgl.node_subgraph(graph, batch)\n",
        "        mini_batch_graph = mini_batch_graph.to(device)  # Move subgraph to the device\n",
        "\n",
        "        # Extract features and labels for the mini-batch\n",
        "        scalar_feats = mini_batch_graph.ndata['scalar_feats'].to(device)\n",
        "        coords = mini_batch_graph.ndata['coords'].to(device)\n",
        "        vector_feats = mini_batch_graph.ndata['vector_feats'].to(device)\n",
        "        esm_feats = mini_batch_graph.ndata['esm'].to(device)\n",
        "        labels = data_y[mini_batch_graph.ndata[dgl.NID].to('cpu')].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(mini_batch_graph, scalar_feats, coords, vector_feats, esm_feats)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(batch)\n",
        "        count += len(batch)\n",
        "\n",
        "    return total_loss / count\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_with_esm(model, data_loader, graph, data_y, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for batch in tqdm(data_loader, desc=\"Evaluation\"):\n",
        "        # Ensure the batch is on the same device as the graph\n",
        "        batch = batch.to(graph.device)\n",
        "\n",
        "        # Sample a mini-batch subgraph\n",
        "        mini_batch_graph = dgl.node_subgraph(graph, batch)\n",
        "        mini_batch_graph = mini_batch_graph.to(device)  # Move subgraph to the device\n",
        "\n",
        "        # Extract features and labels for the mini-batch\n",
        "        scalar_feats = mini_batch_graph.ndata['scalar_feats'].to(device)\n",
        "        coords = mini_batch_graph.ndata['coords'].to(device)\n",
        "        vector_feats = mini_batch_graph.ndata['vector_feats'].to(device)\n",
        "        esm_feats = mini_batch_graph.ndata['esm'].to(device)\n",
        "        labels = data_y[mini_batch_graph.ndata[dgl.NID].to('cpu')].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(mini_batch_graph, scalar_feats, coords, vector_feats, esm_feats)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        total_loss += loss.item() * len(batch)\n",
        "        count += len(batch)\n",
        "\n",
        "    return total_loss / count"
      ],
      "metadata": {
        "id": "M-fUVRVjQ939"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "scalar_input_dim = graph.ndata['scalar_feats'].shape[1]\n",
        "vector_input_dim = graph.ndata['vector_feats'].shape[1]\n",
        "esm_embedding_dim = filtered_esm_embeddings.shape[1]\n",
        "output_dim = data_y.shape[1]\n",
        "\n",
        "model = GVP_ESM_GCN(\n",
        "    scalar_input_dim=scalar_input_dim,\n",
        "    vector_input_dim=vector_input_dim,\n",
        "    scalar_hidden_dim=8,\n",
        "    vector_hidden_dim=4,\n",
        "    esm_embedding_dim=esm_embedding_dim,\n",
        "    output_dim=output_dim\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "vD5TV-DxuMLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate pos_weight\n",
        "num_samples = train_mask.shape[0]  # Total number of training samples\n",
        "num_positive_per_class = train_mask.sum(dim=0).float()  # Number of positive samples per class\n",
        "\n",
        "# Avoid division by zero by replacing zero counts with a very small number\n",
        "num_positive_per_class[num_positive_per_class == 0] = float('inf')  # To avoid division by zero\n",
        "pos_weight = num_samples / (2 * num_positive_per_class)\n",
        "\n",
        "# Replace inf values with 0.0 or any default value you prefer\n",
        "pos_weight[torch.isinf(pos_weight)] = 0.0\n",
        "\n",
        "# Pass pos_weight to BCEWithLogitsLoss\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "# save train and val loss\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_with_esm_epoch(model, train_loader, graph, data_y, criterion, optimizer)\n",
        "    val_loss = evaluate_with_esm(model, val_loader, graph, data_y, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)"
      ],
      "metadata": {
        "id": "BC51EACCQS5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_on_test_set_with_esm(model, test_loader, graph, data_y):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set using Fmax and AUPR metrics.\n",
        "\n",
        "    Parameters:\n",
        "        model: Trained GVP-GCN model.\n",
        "        test_loader: DataLoader for the test set.\n",
        "        graph: Original DGL graph.\n",
        "        data_y: Ground-truth labels for all nodes.\n",
        "\n",
        "    Returns:\n",
        "        fmax: Average maximum F1 score across proteins.\n",
        "        aupr: Average area under precision-recall curve across GO terms.\n",
        "        f1_max_scores: numpy array of Fmax values.\n",
        "        aupr_scores: numpy array of AUPR values.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n",
        "        # Ensure batch is on the same device as the graph\n",
        "        batch = batch.to(graph.device)\n",
        "\n",
        "        # Sample a mini-batch subgraph\n",
        "        mini_batch_graph = dgl.node_subgraph(graph, batch)\n",
        "        mini_batch_graph = mini_batch_graph.to(graph.device)\n",
        "\n",
        "        # Extract features for the mini-batch\n",
        "        scalar_feats = mini_batch_graph.ndata['scalar_feats'].to(graph.device)\n",
        "        coords = mini_batch_graph.ndata['coords'].to(graph.device)\n",
        "        vector_feats = mini_batch_graph.ndata['vector_feats'].to(graph.device)\n",
        "        esm_feats = mini_batch_graph.ndata['esm'].to(graph.device)\n",
        "\n",
        "        # Predict outputs\n",
        "        outputs = torch.sigmoid(model(mini_batch_graph, scalar_feats, coords, vector_feats, esm_feats)).cpu().numpy()\n",
        "\n",
        "        # Extract labels for the mini-batch\n",
        "        batch_labels = data_y[mini_batch_graph.ndata[dgl.NID].to('cpu')].to('cpu').numpy()\n",
        "\n",
        "        predictions.append(outputs)\n",
        "        labels.append(batch_labels)\n",
        "\n",
        "    # Concatenate all predictions and labels\n",
        "    predictions = np.vstack(predictions)\n",
        "    labels = np.vstack(labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    fmax, aupr, f1_max_scores, aupr_scores = compute_metrics(predictions, labels)\n",
        "\n",
        "    print(f\"Test Set Evaluation:\")\n",
        "    print(f\"Fmax: {fmax:.4f}, AUPR: {aupr:.4f}\")\n",
        "    return fmax, aupr, f1_max_scores, aupr_scores"
      ],
      "metadata": {
        "id": "6mftpj9DR-xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model and graph to device\n",
        "model = model.to(device)\n",
        "graph = graph.to('cpu')\n",
        "data_y = data_y.to(device)"
      ],
      "metadata": {
        "id": "k3IoAt9_bGTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "# Get test node IDs\n",
        "test_nids = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
        "\n",
        "# Create a dataset and data loader for the test set\n",
        "test_dataset = NodeDataset(test_nids)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)  # No need to shuffle the test set\n",
        "\n",
        "fmax, aupr, f1_max_scores, aupr_scores = evaluate_on_test_set_with_esm(\n",
        "    model, test_loader, graph, data_y\n",
        ")"
      ],
      "metadata": {
        "id": "Kk9jZ31PT55B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "liCpyk9zUqxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "vn6KYOtTGQ6g",
        "yb9cJ30w12VO",
        "uF2A8oyN14Md",
        "x449li9P4LJE",
        "kV0DoVSg4FMk",
        "JuW2wYT2xVxo"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}